\documentclass[10pt,a4paper,oneside,notitlepage]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[table]{xcolor}  
\usepackage[margin=2.5cm]{geometry}
\usepackage{titling}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{float}
\usepackage{listings}
%\graphicspath{ {plots/} }

% kein einrücken bei neuen absätzen
\setlength{\parindent}{0pt}

% position titel
\setlength{\droptitle}{-2cm}

% abstand vor subsection titel
\titlespacing{\subsection}{0pt}{40pt}{8pt}

\author{Flurin Rindisbacher}
\title{How To Write Fast Numerical Code \\ \vspace{6 mm} \textbf{Assignment 2}}

\begin{document}
\maketitle

\section*{Exercise 2 - Vandermonde determinants}

Please see the last page for the used compiler version and flags.

\subsection*{(a)}
Number of iterations in the innermost loop: $\sum\limits_{j=1}^{n-1} j = \frac{(n-1)*n}{2} = \frac{n^2 -n}{2}$ \\
With one subtraction (counted as one (-) addition?) and one multiplication per iteration this results in $\underline{OPCOUNT = n^2-n}$ floating point operations.  

\subsection*{(b)}
see vandermonde/vandermonde.cpp in the zip file.

\subsection*{(c) / (d)}

\begin{tabular}{|c|c|c|c|c|c|}
\hline
\rowcolor{gray!30} 
\textbf{N} & \textbf{Test passed} & \textbf{flops/cycle (optimized)} & \textbf{cycles (optimized)} & \textbf{flops/cycle} & \textbf{cycles} \\ 
\hline 
1 & 1 & 0.000 & 9 & 0.000 & 9 \\ \hline
2 & 1 & 0.222 & 9 & 0.222 & 9 \\ \hline
4 & 1 & 0.461 & 26 & 0.444 & 27 \\ \hline
8 & 1 & 0.584 & 96 & 0.564 & 99  \\ \hline
16 & 1 & 0.654 & 367 & 0.431 & 556  \\ \hline
32 & 1 & 1.195 & 830 & 0.409 & 2427  \\ \hline
64 & 1 & 1.323 & 3048 & 0.302 & 13345  \\ \hline
128 & 1 & 1.237 & 13146 & 0.359 & 45267  \\ \hline
256 & 1 & 1.246 & 52371 & 0.393 & 166258  \\ \hline
512 & 1 & 1.180 & 221743 & 0.397 & 659474  \\ \hline
1024 & 1 & 1.191 & 879349 & 0.399 & 2623483  \\ \hline
2048 & 1 & 1.197 & 3501235 & 0.400 & 10492388  \\ \hline
4096 & 1 & 1.196 & 14018594 & 0.400 & 41957752  \\ \hline
\end{tabular} 

\begin{itemize}
\item a
\end{itemize}

\subsection*{Exercise 3 - Optimization Blockers}
\subsection*{(a)}
Here's an overview of the things I optimized. Please see the code in the zip-file for details.
Each optimized function has a comment what has been imporoved to the previous function. \\
Optimized:
\begin{itemize}
\item removed the calls to f() by inlining
\item directly access the matrix-elements instead of using get/set\_elt (and therefore bypassing the unnecessary range-checks)
\item compute sin() only once per i-value
\item removed the *\_smat\_counter() calls by directly accessing the variable
\item unrolled the loop several times to benefit from ILP
\end{itemize}

\subsection*{(b), (c), (d)}
Please see the code in the zip file. The used compiler version and optimizer flags can be found on the last page

\subsection*{(e)}

\begin{tabular}{|l|c|c|c|c|c|}
\hline 
\rowcolor{gray!30} 
 (flops/cycle) & \textbf{superslow} & \textbf{f() inlined} & \textbf{trigo} & \textbf{unroll} & \textbf{unroll2} \\ 
\hline 
\cellcolor{gray!30} \textbf{optimization flags} & 0.0174 & 0.0333 & 0.3180 & 0.4719 & 0.5828 \\ 
\hline 
\cellcolor{gray!30} \textbf{no optimization flags} & 0.0146 & 0.0240 & 0.0766 & 0.0918 & 0.1016 \\ 
\hline 
\end{tabular}  \\ \\
The table above shows the flops/cycle for each of my four functions and the superslow function as a baseline. Going from left to right each column represents a function that took the left column and did some imporovements. 'unroll2' on the right side is the last and best optimization. 'f() inlined' is the function where calls to f() have been removed. additionally r/rw access to the matrix-elements go directly to the array instead of calling the functions. 'trigo' decreases the number of sin() computations by reusing the values for each row. 'unroll' unrolled the loop 3 times. 'unroll2' unrolled the loop some more time to benefit from the fact that there is no dependency between the different matrix elements.
\\ \\
It's very satisfactory to see that my last optimization (unroll2) got a speedup of factor 50 compared to the superslow function. Although I knew that trigonometric function are expensive I was surprised of the impact it had on my functions.  The step from 'f() inlined' to 'trigo()' shows this optimization. With optimization flags I got a speedup of factor ten. without I stillt got a speedup of factor three. Comparing the 'trigo' and 'unroll2' columns in the two rows shows how the compiler optimization flags help. The bottom row improves a little by unrolling but the row with optimization flags benefits a lot from the unrolled function due to the fact that the matrix elements can be calculated  (almost) independently from each other. There's no dependency between the elements as long as the  smat\_counter is correctly set. \\

A word about unrolling. Under the assumption that my Ivy Bridge processor has latency 5 for multiplication and needs 1 cycle per issue I thought it would be best to use $\#accumulators = ceil(latency/cycles per issue) = 5 / 1 = 5$ as a good number of accumulators. 'unroll' starts with three accumulators because it's easy to implement. I then went beyond those 5 accumulators because I was still seeing improvement with each unroll. see the unroll2 function for details.

\subsection*{Exercise 4 - Locality of Gaussian Elimination }

\begin{lstlisting}[ numbers=left,]
double A[N][N], tmp ;
for (int k=0 ; k<N; k++){
    double max_p = abs(A[k][k]);
    int ind_p = k;
    // Find Pivot
    for(int i = k+1; i < N; i++){
        tmp = abs (A[i][k]) ;
        if (tmp > max_p){
            max_p = tmp ;
            ind_p = i ;
        }
    }
    // // Swap row containing pivot with k-th row
    for (int j = 0 ; j < N; j++){
        tmp = A[ind_p][j] ;
        A[ind_p][j] = A[k][j] ;
        A[k][j] = tmp ;
    }
    // Main Loop for Gaussian Elimination
    for (int i = k+1; i < N; i ++){
        for (int j = k+1; j < N; j ++){
            A[i][j] = A[i][j] - A[k][j] * (A[i][k] / A[k][k]) ;
        }
        A[i][k] = 0 ;
    }
}
\end{lstlisting}

C is row-major. Searching for the pivot on line 6/7 does therefore not benefit from spatial locality because it accesses columns. But inside the 'Find Pivot' for-loop we have temporal locality because the memory location A[i][k] is used several times (as the the tmp variable). \\
The for loop to swap rows on lines 14 to 18 has spatial locality. The A[ind\_p] and A[k] rows are accessed. \\
The accesses to A[i][j] on line 22 has temporal locality. It is read, therefore stored in cache and later written (which is written to the cache too in our architecture). On the same line A[i][j] and A[k][j] also have spatial locality because the rows i and k are accessed in the correct order. For small j (j=k+1) there could be spatial locality when A[i][k] and A[i][j] are in the same block. With increasing j and depending on the blocksize (probably 8 doubles) this locality is lost. \\
\textbf{Summary:}
\begin{itemize}
\item temporal locality inside the 'Find pivot' loop
\item lines 14 to 18 has spatial locality
\item line 22 has temporal locality (A[i][j] is read and written)
\item line 22 spatial locality for A[i][j] and A[k][j] because they are accessed as rows
\item line 22 A[i][k] and A[i][j] may benefit from spatial locality when j and k are near (when abs(k - j) is below 8 means they are in the same block )
\end{itemize}

\newpage

\section*{Compiler Version and Flags}
\label{compiler_version}
If not stated otherwise all exercises have been compiled using: \\ 

\underline{Compiler Version}
\begin{verbatim}
[fri@arc vandermonde]$ gcc --version
gcc (GCC) 4.9.2 20150304 (prerelease)
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[fri@arc vandermonde]$
\end{verbatim}

\underline{Used compiler flags for \textbf{vandermonde} exercise} 
\begin{verbatim}
-O3 -m64 -mno-abm -fno-tree-vectorize
\end{verbatim}

\underline{Used compiler flags for \textbf{optimization blockers} exercise (a),(b),(c)} 
\begin{verbatim}
-O3 -m64 -march=corei7-avx
\end{verbatim}

\underline{Used compiler flags for \textbf{optimization blockers} exercise (d)} 
\begin{verbatim}
-O0
\end{verbatim}
\end{document}
